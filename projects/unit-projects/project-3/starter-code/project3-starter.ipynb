{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n",
    "\n",
    "In this project, you will perform a logistic regression on the admissions data we've been working with in projects 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "df = df_raw.dropna() \n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Frequency Tables\n",
    "\n",
    "#### 1. Let's create a frequency table of our variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>admit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>93</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "admit      0   1\n",
       "prestige        \n",
       "1.0       28  33\n",
       "2.0       95  53\n",
       "3.0       93  28\n",
       "4.0       55  12"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequency table for prestige and whether or not someone was admitted\n",
    "pd.crosstab(df['prestige'], df.admit)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('gre', array([ 0.00208469,  0.01773589]))]\n",
      "[('gre', -2.0331085041348724)]\n",
      "[ 0.2356103   0.3561485   0.42692446  0.34472061  0.28964642  0.4023858\n",
      "  0.30728832  0.24147593  0.30001014  0.37653101  0.42692446  0.25755147\n",
      "  0.40665806  0.37304007  0.37686415  0.27459271  0.41619576  0.22492111\n",
      "  0.42584     0.30157681  0.28200472  0.35598584  0.32469516  0.36379283\n",
      "  0.40387944  0.42544976  0.33702678  0.29261116  0.41339738  0.29096188\n",
      "  0.30146475  0.40387944  0.32695479  0.42692446  0.2267195   0.24137849\n",
      "  0.31727032  0.28953695  0.2818611   0.28873497  0.30517821  0.3175393\n",
      "  0.32597982  0.28250775  0.37245952  0.26640081  0.31807764  0.28128705\n",
      "  0.2550498   0.24235414  0.34740978  0.25724636  0.39396739  0.36412129\n",
      "  0.35480754  0.39663831  0.3080817   0.23347692  0.24333247  0.32469516\n",
      "  0.33532485  0.30857341  0.34664618  0.36650638  0.32015862  0.32769677\n",
      "  0.39502653  0.33579938  0.3189631   0.42575327  0.34797294  0.20490555\n",
      "  0.2744161   0.32015862  0.38439363  0.38670453  0.30872479  0.42692446\n",
      "  0.29900546  0.33857405  0.37229372  0.33489016  0.28035574  0.23338171\n",
      "  0.28355147  0.28982891  0.32664263  0.32726709  0.37387006  0.35749172\n",
      "  0.37615636  0.38519136  0.42649059  0.31604223  0.35521365  0.35476694\n",
      "  0.3460439   0.27505222  0.37221083  0.2422239   0.2195236   0.31850096\n",
      "  0.2347171   0.30206267  0.35728806  0.39227484  0.3750333   0.27349889\n",
      "  0.24098898  0.27462804  0.36334141  0.25029154  0.22628448  0.32625266\n",
      "  0.38603174  0.33853433  0.25833227  0.37569865  0.42562319  0.21882548\n",
      "  0.29261116  0.27188081  0.28935457  0.28132291  0.3861999   0.2999729\n",
      "  0.32750143  0.39553527  0.29926575  0.26536226  0.33528532  0.34311985\n",
      "  0.31784686  0.28168163  0.30717507  0.28344339  0.30861125  0.37686415\n",
      "  0.33619507  0.32765769  0.34769131  0.37486703  0.33833578  0.31784686\n",
      "  0.31784686  0.23503583  0.27445142  0.30626993  0.27272427  0.39371335\n",
      "  0.42579663  0.24245185  0.34773153  0.31807764  0.33734388  0.31577392\n",
      "  0.30555442  0.27508758  0.35541678  0.37611474  0.32590189  0.34596363\n",
      "  0.3750333   0.28891712  0.31746244  0.37686415  0.2576193   0.38573753\n",
      "  0.2849949   0.327814    0.24287558  0.29785432  0.36498409  0.42445293\n",
      "  0.28329933  0.33607634  0.28851648  0.33552253  0.33591807  0.20516573\n",
      "  0.3377008   0.28456141  0.37686415  0.30168889  0.2806421   0.42518966\n",
      "  0.30967187  0.3076282   0.28265158  0.34371972  0.4249296   0.34700779\n",
      "  0.23554642  0.32722805  0.30959604  0.35371208  0.24196356  0.32785308\n",
      "  0.3192714   0.42393308  0.31707826  0.37686415  0.25199268  0.32887007\n",
      "  0.41589414  0.3946875   0.34648553  0.29915418  0.31823154  0.39384036\n",
      "  0.31638737  0.34548221  0.32757955  0.35306364  0.21876485  0.26705989\n",
      "  0.26477489  0.30959604  0.2996006   0.36708308  0.27311141  0.42462625\n",
      "  0.42215822  0.3846035   0.3369079   0.29863385  0.27455738  0.38426773\n",
      "  0.31742401  0.32648662  0.23487643  0.24783685  0.42488626  0.33481116\n",
      "  0.27657552  0.28089281  0.37457614  0.2559945   0.29286821  0.36284922\n",
      "  0.33548299  0.29870815  0.42653397  0.36440879  0.25738193  0.36564205\n",
      "  0.34688724  0.35468574  0.33544345  0.29356657  0.30060642  0.39460276\n",
      "  0.34536191  0.29099848  0.33837549  0.29176751  0.34720876  0.3634645\n",
      "  0.25731414  0.29059612  0.33837549  0.29319889  0.23474896  0.30827077\n",
      "  0.32789217  0.36490188  0.28071372  0.34777176  0.29978672  0.36576547\n",
      "  0.35472634  0.29034025  0.3253177   0.26751145  0.31853945  0.36301325\n",
      "  0.35399594  0.35724733  0.22712398  0.35525427  0.29026717  0.25812844\n",
      "  0.32660363  0.42354331  0.35627052  0.42324021  0.24648379  0.33639301\n",
      "  0.42163912  0.36588891  0.42679429  0.27145969  0.29081555  0.30796829\n",
      "  0.26508575  0.30042001  0.3841838   0.34516144  0.35586386  0.24170341\n",
      "  0.36704187  0.17883163  0.31807764  0.29919137  0.31827002  0.29904264\n",
      "  0.25673837  0.31115249  0.3561485   0.3565553   0.29228087  0.30027093\n",
      "  0.20467449  0.21906812  0.41516187  0.2755476   0.2996006   0.26532768\n",
      "  0.26685165  0.2814305   0.24790298  0.28880782  0.3667123   0.36428556\n",
      "  0.30917919  0.31761618  0.28114365  0.39663831  0.35582321  0.2487969\n",
      "  0.30898981  0.26705989  0.33742318  0.2904499   0.33496918  0.29930295\n",
      "  0.35533552  0.28222024  0.30604388  0.28481423  0.31654083  0.29118147\n",
      "  0.28150224  0.32675967  0.31938705  0.24238671  0.33402162  0.41675609\n",
      "  0.33631383  0.3167711   0.37486703  0.30146475  0.40157572  0.37382855\n",
      "  0.38380623  0.30997527  0.38645218  0.29356657  0.30038274  0.36358761\n",
      "  0.26636615  0.30872479  0.2722672   0.2646023   0.33710604  0.32015862\n",
      "  0.42644721  0.3014274   0.36613584  0.36063795  0.33607634  0.31031679\n",
      "  0.30921707  0.33710604  0.42692446  0.34444022  0.29744647  0.3754075\n",
      "  0.30038274  0.30045729  0.35749172  0.27170529  0.24899584  0.39604423\n",
      "  0.31769306  0.34464049  0.34600377  0.42280733  0.35700302  0.32687674\n",
      "  0.33758181  0.26827671  0.33857405  0.30751488  0.26356824  0.3754075\n",
      "  0.32887007]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "feature_cols = ['gre', 'gpa']\n",
    "X = df[feature_cols]\n",
    "y = df['admit']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "\n",
    "print zip(feature_cols,logreg.coef_)\n",
    "print zip(feature_cols,logreg.intercept_)\n",
    "\n",
    "# examine some example predictions\n",
    "print logreg.predict_proba(X)[:,1]\n",
    "#print logreg.predict_proba(2)\n",
    "#print logreg.predict_proba(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Return of dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Create class or dummy variables for prestige "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prestige_1.0</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige  prestige_1.0  prestige_2.0  prestige_3.0  \\\n",
       "0      0  380.0  3.61       3.0           0.0           0.0           1.0   \n",
       "1      1  660.0  3.67       3.0           0.0           0.0           1.0   \n",
       "2      1  800.0  4.00       1.0           1.0           0.0           0.0   \n",
       "3      1  640.0  3.19       4.0           0.0           0.0           0.0   \n",
       "4      0  520.0  2.93       4.0           0.0           0.0           0.0   \n",
       "\n",
       "   prestige_4.0  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           1.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_prestige = pd.get_dummies(df['prestige'],prefix='prestige')\n",
    "df = df.join(dum_prestige)\n",
    "\n",
    "#del df['1.0'] - Unable to delete the dummy columns 1.0/2.0/3.0/4.0\n",
    "#dum_prestige\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 When modeling our class variables, how many do we need? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: While creating dummy/class variable for any feature we need n-1 dummy vairables for a feature with n different options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Hand calculating odds ratios\n",
    "\n",
    "Develop your intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_1.0  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61           0.0           0.0           1.0           0.0\n",
      "1      1  660.0  3.67           0.0           0.0           1.0           0.0\n",
      "2      1  800.0  4.00           1.0           0.0           0.0           0.0\n",
      "3      1  640.0  3.19           0.0           0.0           0.0           1.0\n",
      "4      0  520.0  2.93           0.0           0.0           0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "handCalc = df[cols_to_keep].join(dum_prestige.ix[:, 'prestige_1':])\n",
    "print handCalc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prestige_1.0', array([ 2.79576381]))]\n",
      "[('prestige_1.0', 0.39395734648013914)]\n"
     ]
    }
   ],
   "source": [
    "#crosstab prestige 1 admission \n",
    "# frequency table cutting prestige and whether or not someone was admitted\n",
    "feature_cols = ['prestige_1.0']\n",
    "X = df[feature_cols]\n",
    "y = df['admit']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "\n",
    "print zip(feature_cols,np.exp(logreg.coef_))\n",
    "print zip(feature_cols,np.exp(logreg.intercept_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Use the cross tab above to calculate the odds of being admitted to grad school if you attended a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.10141169]]\n",
      "[[ 0.52412942]]\n"
     ]
    }
   ],
   "source": [
    "logodds = logreg.intercept_\n",
    "odds = np.exp(logodds) * np.exp(1 * logreg.coef_)\n",
    "prob = odds/(1+odds)\n",
    "\n",
    "print odds\n",
    "print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Now calculate the odds of admission if you did not attend a #1 ranked college"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('prestige_2.0', -0.53631146023411969), ('prestige_3.0', -1.1176217983220713), ('prestige_4.0', -1.3586152635177717)]\n",
      "intercept [-0.0315439]\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['prestige_2.0','prestige_3.0','prestige_4.0']\n",
    "X = df[feature_cols]\n",
    "y = df['admit']\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X,y)\n",
    "\n",
    "print zip(feature_cols,logreg.coef_[0])\n",
    "print 'intercept',logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Calculate the odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96894842]\n",
      "[ 0.49211468]\n"
     ]
    }
   ],
   "source": [
    "logodds = logreg.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds/(1+odds)\n",
    "\n",
    "print odds\n",
    "print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Write this finding in a sentenance: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Probability of getting admission with #1 ranked college is 28% while the combined probability of getting admission for a Ranked 2,3 and 4 school is 49% which shows that the prestige of school is a deciding factor in getting admission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Print the cross tab for prestige_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1190a4050>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhoAAAGPCAYAAAAa+nlLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117d73790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.crosstab(df['prestige_4.0'], df.admit.astype(bool)).plot(kind='bar')\n",
    "plt.title ('Admission based on Prestige level 4')\n",
    "plt.xlabel ('Prestige of School as 4')\n",
    "plt.ylabel ('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Calculate the OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Write this finding in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0\n",
      "0      0  380.0  3.61           0.0           1.0           0.0\n",
      "1      1  660.0  3.67           0.0           1.0           0.0\n",
      "2      1  800.0  4.00           0.0           0.0           0.0\n",
      "3      1  640.0  3.19           0.0           0.0           1.0\n",
      "4      0  520.0  2.93           0.0           0.0           1.0\n"
     ]
    }
   ],
   "source": [
    "# create a clean data frame for the regression\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "data = df[cols_to_keep].join(dum_prestige.ix[:, 'prestige_2':])\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to add a constant term for our Logistic Regression. The statsmodels function we're going to be using requires that intercepts/constants are specified explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2.0</th>\n",
       "      <th>prestige_3.0</th>\n",
       "      <th>prestige_4.0</th>\n",
       "      <th>intercept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit    gre   gpa  prestige_2.0  prestige_3.0  prestige_4.0  intercept\n",
       "0      0  380.0  3.61           0.0           1.0           0.0        1.0\n",
       "1      1  660.0  3.67           0.0           1.0           0.0        1.0\n",
       "2      1  800.0  4.00           0.0           0.0           0.0        1.0\n",
       "3      1  640.0  3.19           0.0           0.0           1.0        1.0\n",
       "4      0  520.0  2.93           0.0           0.0           1.0        1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually add the intercept\n",
    "data['intercept'] = 1.0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Set the covariates to a variable called train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cols = ['gre','gpa','prestige_2.0','intercept']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-76f9f1ef9dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madmit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "X = data[train_cols]\n",
    "y = data.admit\n",
    "\n",
    "logreg = LinearRegression()\n",
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Print the summary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print zip(train_cols,logreg.coef_)\n",
    "print zip(train_cols,logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Calculate the odds ratios of the coeffiencents and their 95% CI intervals\n",
    "\n",
    "hint 1: np.exp(X)\n",
    "\n",
    "hint 2: conf['OR'] = params\n",
    "        \n",
    "           conf.columns = ['2.5%', '97.5%', 'OR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logodds = logreg.coef_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds/(1+odds)\n",
    "\n",
    "print odds\n",
    "print prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Interpret the OR of Prestige_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 Interpret the OR of GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predicted probablities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a way of evaluating our classifier, we're going to recreate the dataset with every logical combination of input values. This will allow us to see how the predicted probability of admission increases/decreases across different variables. First we're going to generate the combinations using a helper function called cartesian (above).\n",
    "\n",
    "We're going to use np.linspace to create a range of values for \"gre\" and \"gpa\". This creates a range of linearly spaced values from a specified min and maximum value--in our case just the min/max observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cartesian(arrays, out=None):\n",
    "    \"\"\"\n",
    "    Generate a cartesian product of input arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : list of array-like\n",
    "        1-D arrays to form the cartesian product of.\n",
    "    out : ndarray\n",
    "        Array to place the cartesian product in.\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        2-D array of shape (M, len(arrays)) containing cartesian products\n",
    "        formed of input arrays.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> cartesian(([1, 2, 3], [4, 5], [6, 7]))\n",
    "    array([[1, 4, 6],\n",
    "           [1, 4, 7],\n",
    "           [1, 5, 6],\n",
    "           [1, 5, 7],\n",
    "           [2, 4, 6],\n",
    "           [2, 4, 7],\n",
    "           [2, 5, 6],\n",
    "           [2, 5, 7],\n",
    "           [3, 4, 6],\n",
    "           [3, 4, 7],\n",
    "           [3, 5, 6],\n",
    "           [3, 5, 7]])\n",
    "    \"\"\"\n",
    "\n",
    "    arrays = [np.asarray(x) for x in arrays]\n",
    "    dtype = arrays[0].dtype\n",
    "\n",
    "    n = np.prod([x.size for x in arrays])\n",
    "    if out is None:\n",
    "        out = np.zeros([n, len(arrays)], dtype=dtype)\n",
    "\n",
    "    m = n / arrays[0].size\n",
    "    out[:,0] = np.repeat(arrays[0], m)\n",
    "    if arrays[1:]:\n",
    "        cartesian(arrays[1:], out=out[0:m,1:])\n",
    "        for j in xrange(1, arrays[0].size):\n",
    "            out[j*m:(j+1)*m,1:] = out[0:m,1:]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# instead of generating all possible values of GRE and GPA, we're going\n",
    "# to use an evenly spaced range of 10 values from the min to the max \n",
    "gres = np.linspace(data['gre'].min(), data['gre'].max(), 10)\n",
    "print gres\n",
    "# array([ 220.        ,  284.44444444,  348.88888889,  413.33333333,\n",
    "#         477.77777778,  542.22222222,  606.66666667,  671.11111111,\n",
    "#         735.55555556,  800.        ])\n",
    "gpas = np.linspace(data['gpa'].min(), data['gpa'].max(), 10)\n",
    "print gpas\n",
    "# array([ 2.26      ,  2.45333333,  2.64666667,  2.84      ,  3.03333333,\n",
    "#         3.22666667,  3.42      ,  3.61333333,  3.80666667,  4.        ])\n",
    "\n",
    "\n",
    "# enumerate all possibilities\n",
    "combos = pd.DataFrame(cartesian([gres, gpas, [1, 2, 3, 4], [1.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Recreate the dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# recreate the dummy variables\n",
    "\n",
    "# keep only what we need for making predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Make predictions on the enumerated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Interpret findings for the last 4 observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Plot the probability of being admitted into graduate school, stratified by GPA and GRE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
